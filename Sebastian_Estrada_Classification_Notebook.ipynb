{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOpSFxmFEuWZ2alxuR2Vb9g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sael17/Project_2_Notebooks_AISP23/blob/master/Sebastian_Estrada_Classification_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Student Name: Sebastian A. Estrada Lopez\n",
        "# Student Number: 802-19-3839"
      ],
      "metadata": {
        "id": "0HGfxjOjl4Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries to be used and set up\n",
        "\n",
        "Some of the libraries that are going to be used in here are common ones like numpy, matplotlib and PyTorch 2.0"
      ],
      "metadata": {
        "id": "UDy-fcG4l72O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_R2ZIulk0uX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make NumPy printouts easier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "# Check Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "v4AMqw1PnyxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper Parameters\n",
        "\n",
        "In this section, we will define the hyper paramaters to be used in the models created for this experiment."
      ],
      "metadata": {
        "id": "-TuVPOtzoPco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Hyper-parameters for this experiment\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "xkpVFYGpmGym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtaining and loading the datasets\n",
        "\n",
        "In this experiment, the datasets will be loaded from MNIST. From these data sets we will be classifying images of numbers 0-9. We will classify if an image corresponds to one of those numbers, and if it does, which one. Once the dataset is downloaded, it is normalized and transformed into a tensor as well. So there is no need for us to do the normalization manually."
      ],
      "metadata": {
        "id": "Ynh7srMPp320"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Load the Datasets from MNIST '''\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                          train=True,\n",
        "                                          transform=transforms.ToTensor(),\n",
        "                                          download=True)\n",
        "\n",
        "# Why dont we have to download this one??\n",
        "test_dataset = torchvision.datasets.MNIST(root='../..data',\n",
        "                                         train=False,\n",
        "                                         transform=transforms.ToTensor(),\n",
        "                                         download=True)\n",
        "\n",
        "\n",
        "'''Data loaders for pytorh'''\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "NrPmej5tqvqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models Design\n",
        "\n",
        "In this section, we will build the fully connected neural network models to be used in this experiment. Each Model will be unique in the sense that they have different number of neurons and layers."
      ],
      "metadata": {
        "id": "wWLe82wMtJTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model #1\n",
        "\n",
        "Model #1 Consists of the following:\n",
        "\n",
        "\n",
        "Network #1: 4-layer network\n",
        "\n",
        "1.   Layer 1 – 20 neurons\n",
        "2.   Layer 2 – 50 neurons\n",
        "3.   Layer 3 – 20 neurons\n",
        "4.   Layer 4 – output neuron with softmax activation"
      ],
      "metadata": {
        "id": "uwkAehJ8v_tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork_1(torch.nn.Module):\n",
        "  def __init__(self,input_size,num_classes):\n",
        "    super(NeuralNetwork_1,self).__init__()\n",
        "    self.layer1 = torch.nn.Linear(input_size, 20)\n",
        "    self.layer2 = torch.nn.Linear(20,50)\n",
        "    self.layer3 = torch.nn.Linear(50,20)\n",
        "    self.layer4 = torch.nn.Linear(20,num_classes)\n",
        "    self.hidden_activation = torch.nn.ReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    y_train = self.layer1(x)\n",
        "    y_train = self.hidden_activation(y_train)\n",
        "    y_train = self.layer2(y_train)\n",
        "    y_train = self.hidden_activation(y_train)\n",
        "    y_train = self.layer3(y_train)\n",
        "    y_train = self.hidden_activation(y_train)\n",
        "    y_train = self.layer4(y_train)\n",
        "    return y_train\n",
        "\n",
        "\n",
        "model_1 = NeuralNetwork_1(input_size,num_classes).to(device)"
      ],
      "metadata": {
        "id": "9Fera6xLwbLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model #2\n",
        "\n",
        "Model #2 Consists of the following:\n",
        "\n",
        "\n",
        "Network #2: 6- layer network\n",
        "\n",
        "1.   Layer 1 – 10 neurons\n",
        "2.   Layer 2 – 20 neurons\n",
        "3.   Layer 3 – 30 neurons\n",
        "4.   Layer 4 - 20 neurons\n",
        "5.   Layer 5 - 10 neurons\n",
        "6.   Layer 6 – output neuron with softmax activation"
      ],
      "metadata": {
        "id": "tbmJCcU-3zgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork_2(torch.nn.Module):\n",
        "  def __init__(self,input_size,num_classes):\n",
        "    super(NeuralNetwork_2,self).__init__()\n",
        "    self.layer1 = torch.nn.Linear(input_size, 10)\n",
        "    self.layer2 = torch.nn.Linear(10,20)\n",
        "    self.layer3 = torch.nn.Linear(20,30)\n",
        "    self.layer4 = torch.nn.Linear(30,20)\n",
        "    self.layer5 = torch.nn.Linear(20,10)\n",
        "    self.layer6 = torch.nn.Linear(10,num_classes)\n",
        "    self.hidden_activation = torch.nn.ReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    y_train = self.layer1(x)\n",
        "    y_train = self.hidden_activation(y_train)\n",
        "    y_train = self.layer2(y_train)\n",
        "    y_train = self.hidden_activation(y_train)\n",
        "    y_train = self.layer3(y_train)\n",
        "    y_train = self.hidden_activation(y_train)\n",
        "    y_train = self.layer4(y_train)\n",
        "    y_train = self.hidden_activation(y_train)\n",
        "    y_train = self.layer5(y_train)\n",
        "    y_train = self.hidden_activation(y_train)\n",
        "    y_train = self.layer6(y_train)\n",
        "    return y_train\n",
        "\n",
        "\n",
        "model_2 = NeuralNetwork_2(input_size,num_classes).to(device)"
      ],
      "metadata": {
        "id": "m8_RJrzg4axp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model #3\n",
        "\n",
        "Model #3 Consists of the following:\n",
        "\n",
        "\n",
        "Network #3: 6- layer network\n",
        "\n",
        "1.   Layer 1 – 10 neurons\n",
        "2.   Layer 2 – 40 neurons\n",
        "3.   Layer 3 – 70 neurons\n",
        "4.   Layer 4 - 40 neurons\n",
        "5.   Layer 5 - 10 neurons\n",
        "6.   Layer 6 – output neuron with softmax activation"
      ],
      "metadata": {
        "id": "UUpwlHbj5NGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork_3(torch.nn.Module):\n",
        "  def __init__(self,input_size,num_classes):\n",
        "    super(NeuralNetwork_3,self).__init__()\n",
        "    self.layer1 = torch.nn.Linear(input_size, 10)\n",
        "    self.layer2 = torch.nn.Linear(10,40)\n",
        "    self.layer3 = torch.nn.Linear(40,70)\n",
        "    self.layer4 = torch.nn.Linear(70,40)\n",
        "    self.layer5 = torch.nn.Linear(40,10)\n",
        "    self.layer6 = torch.nn.Linear(10,num_classes)\n",
        "    self.hidden_activation = torch.nn.ReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    y_train = self.layer1(x)\n",
        "    y_train = self.hidden_activation(y_train)\n",
        "    y_train = self.layer2(y_train)\n",
        "    y_train = self.hidden_activation(y_train)\n",
        "    y_train = self.layer3(y_train)\n",
        "    y_train = self.hidden_activation(y_train)\n",
        "    y_train = self.layer4(y_train)\n",
        "    y_train = self.hidden_activation(y_train)\n",
        "    y_train = self.layer5(y_train)\n",
        "    y_train = self.hidden_activation(y_train)\n",
        "    y_train = self.layer6(y_train)\n",
        "    return y_train\n",
        "\n",
        "\n",
        "model_3 = NeuralNetwork_3(input_size,num_classes).to(device)"
      ],
      "metadata": {
        "id": "TPdssIgy5aBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "1QqV5zgu7F6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "total_step = len(train_loader)\n",
        "def train_model(model):\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  for epoch in range(num_epochs):\n",
        "    for i, (images,labels) in enumerate(train_loader):\n",
        "      # move tensors to the configured device\n",
        "      images = images.reshape(-1,28*28).to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Forward pass\n",
        "      y_pred = model(images)\n",
        "      loss = criterion(y_pred,labels)\n",
        "\n",
        "      # Backpropagation and optimization\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "metadata": {
        "id": "JXcUIgNj7cpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Testing"
      ],
      "metadata": {
        "id": "_jjcvtFi9Ems"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model):\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images,labels in test_loader:\n",
        "      images = images.reshape(-1,28*28).to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _,predicted = torch.max(outputs.data,1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "  # Save the model checkpoint\n",
        "  torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "metadata": {
        "id": "ZFY__Dg59JC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models Training & Testing"
      ],
      "metadata": {
        "id": "L6g5V7_h97wd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model #1 Training"
      ],
      "metadata": {
        "id": "eyZTInTXLbpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Model #1\")\n",
        "train_model(model_1)\n",
        "print(\"-------------------\")"
      ],
      "metadata": {
        "id": "v8ISBj3-Da83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model #1 Testing"
      ],
      "metadata": {
        "id": "z1gzoQmJLfgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing Model #1\")\n",
        "test_model(model_1)\n",
        "print(\"-------------------\")"
      ],
      "metadata": {
        "id": "3j99p7RoDe42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model #2 Training"
      ],
      "metadata": {
        "id": "qkM0goNoLjsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Model #2\")\n",
        "train_model(model_2)\n",
        "print(\"-------------------\")"
      ],
      "metadata": {
        "id": "zwcVK6qOHIYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model #2 Testing"
      ],
      "metadata": {
        "id": "OY4vRuwALyVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing Model #2\")\n",
        "test_model(model_2)\n",
        "print(\"-------------------\")"
      ],
      "metadata": {
        "id": "rw3sdHgwHQD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model #3 Training"
      ],
      "metadata": {
        "id": "mfndkUdDL2CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Model #3\")\n",
        "train_model(model_3)\n",
        "print(\"-------------------\")"
      ],
      "metadata": {
        "id": "zR5M08XgHTgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model #3 Testing"
      ],
      "metadata": {
        "id": "vPa9v-PnL5Is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing Model #3\")\n",
        "test_model(model_3)"
      ],
      "metadata": {
        "id": "Bk8Y6XlqHW1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which of the three models had the least amount of error validation? How long it took to train each model? \n",
        "\n",
        "Data From a Test:\n",
        "\n",
        "|Model|Accuracy (Testing data)|Time|\n",
        "|-|-|-|\n",
        "|Network #1|94.57%|6 minutes\n",
        "|Network #2|90.36%|6 minutes|\n",
        "|Network #3|91.90%|6 minutes|\n",
        "\n",
        "However,when doing various tests (running the models again) the same behavior that is shown in the data repeats itself. Model #1 always has better accuracy than the other models, therefore it has the least amount of error validation. It took around 5-6 minutes to train each model.\n",
        "\n",
        "This is also evidence by the loss observed from the models when in the training process.\n",
        "\n",
        "\n",
        "For a run of the experiment, these were the losses from training for the last epoch for every model:\n",
        "\n",
        "\n",
        "\n",
        "1.   Model #1 - Epoch [20/20], Step [1875/1875], Loss: 0.0293\n",
        "2.   Model #2 - Epoch [20/20], Step [1875/1875], Loss: 0.4349\n",
        "3.   Model #3 - Epoch [20/20], Step [1875/1875], Loss: 0.1115\n",
        "\n",
        "\n",
        "This clearly shows how Network #1 has the least amount of error validation.\n",
        "\n",
        "For another run, the accuracy for the models were the following:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Model #1 - 94.77%\n",
        "*   Model #2 - 91.55%\n",
        "*   Model #3 - 92.24%\n",
        "\n",
        "This also confirms that the least amount of error is in Model #1, since it produces the highest accuracy.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-LJGZPpoCmK7"
      }
    }
  ]
}